{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f7c3d6d-043e-49e6-9781-b2c4a1411d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MEMBER 2: NAIVE BAYES AND DEEP LEARNING MODELS\n",
      "================================================================================\n",
      "\n",
      "--- PHASE 1: LOADING PREPROCESSED DATA ---\n",
      "Target column: condition\n",
      "Preprocessor loaded successfully\n",
      " Train-test split loaded: 237 train, 60 test samples\n",
      " Data preprocessed: 13 features after transformation\n",
      "\n",
      "--- PHASE 2: NAIVE BAYES MODEL ---\n",
      "\n",
      "Naive Bayes Performance:\n",
      "  Accuracy:  0.8667\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.7143\n",
      "  F1-Score:  0.8333\n",
      "\n",
      "Calculating Bootstrap Confidence Intervals (1000 iterations)...\n",
      "Bootstrap Mean Accuracy: 0.8667\n",
      "95% Confidence Interval: [0.7667, 0.9500]\n",
      "Naive Bayes confusion matrix saved\n",
      "Naive Bayes ROC curve saved\n",
      "Naive Bayes PR curve saved\n",
      "Naive Bayes model and metrics saved\n",
      "\n",
      "--- PHASE 3: MULTILAYER PERCEPTRON (ANN) ---\n",
      "\n",
      "MLP Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m1,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,161</span> (47.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,161\u001b[0m (47.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,161</span> (47.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,161\u001b[0m (47.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MLP model...\n",
      " MLP training completed in 42 epochs\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "\n",
      "MLP Performance:\n",
      "  Accuracy:  0.9167\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.8214\n",
      "  F1-Score:  0.9020\n",
      "MLP training curves saved\n",
      "MLP confusion matrix saved\n",
      "MLP ROC curve saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP PR curve saved\n",
      "MLP model and metrics saved\n",
      "\n",
      "--- PHASE 4: LSTM MODEL (ADVANCED EXTENSION) ---\n",
      "LSTM input shape: (237, 1, 13)\n",
      "\n",
      "LSTM Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,968</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m19,968\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,929</span> (128.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,929\u001b[0m (128.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,929</span> (128.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,929\u001b[0m (128.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM model...\n",
      " LSTM training completed in 49 epochs\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 764ms/step\n",
      "\n",
      "LSTM Performance:\n",
      "  Accuracy:  0.9000\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.7857\n",
      "  F1-Score:  0.8800\n",
      "LSTM training curves saved\n",
      "LSTM confusion matrix saved\n",
      "LSTM ROC curve saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM PR curve saved\n",
      "LSTM model and metrics saved\n",
      "\n",
      "--- PHASE 5: AGGREGATING METRICS ---\n",
      "\n",
      " Aggregated metrics saved to all_models_comparison.csv\n",
      "\n",
      "All Models Performance Comparison:\n",
      "        model  accuracy  precision   recall  f1_score  roc_auc\n",
      "    MLP (ANN)  0.916667   1.000000 0.821429  0.901961 0.950893\n",
      "         LSTM  0.900000   1.000000 0.785714  0.880000 0.947545\n",
      "  Naive Bayes  0.866667   1.000000 0.714286  0.833333 0.912946\n",
      "Random Forest  0.833333   0.875000 0.750000  0.807692 0.919643\n",
      "Decision Tree  0.800000   0.833333 0.714286  0.769231 0.843750\n",
      "Comparison bar chart saved\n",
      "\n",
      "================================================================================\n",
      "MEMBER 2 COMPLETION SUMMARY\n",
      "================================================================================\n",
      "\n",
      " Naive Bayes trained and evaluated with bootstrap CI\n",
      "MLP (ANN) trained and evaluated with training curves\n",
      "LSTM trained and evaluated with training curves\n",
      "All models saved to artifacts/models/\n",
      "All metrics saved to artifacts/metrics/\n",
      "All figures saved to artifacts/figures/\n",
      "Aggregated comparison CSV and chart created\n",
      "\n",
      "Final Model Rankings (by Accuracy):\n",
      "  3. MLP (ANN): 0.9167\n",
      "  2. LSTM: 0.9000\n",
      "  4. Naive Bayes: 0.8667\n",
      "  5. Random Forest: 0.8333\n",
      "  1. Decision Tree: 0.8000\n",
      "\n",
      "================================================================================\n",
      "ALL MODELS READY FOR PRESENTATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Member 2: Naive Bayes and Deep Learning Models\n",
    "Heart Disease Classification using Naive Bayes, MLP, and LSTM\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: IMPORT LIBRARIES AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations and array handling\n",
    "import matplotlib.pyplot as plt  # For creating visualizations\n",
    "import seaborn as sns  # For advanced statistical visualizations\n",
    "from sklearn.naive_bayes import GaussianNB  # For Gaussian Naive Bayes classifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # For model evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve  # For advanced evaluation\n",
    "from sklearn.utils import resample  # For bootstrap sampling\n",
    "import tensorflow as tf  # For deep learning framework\n",
    "from tensorflow import keras  # For high-level neural network API\n",
    "from tensorflow.keras.models import Sequential  # For creating sequential neural networks\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Reshape  # For neural network layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # For preventing overfitting during training\n",
    "import joblib  # For loading saved models and preprocessors\n",
    "import json  # For saving and loading metrics\n",
    "import os  # For directory and file operations\n",
    "import glob  # For file pattern matching\n",
    "import warnings  # For suppressing unnecessary warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n",
    "\n",
    "# Set random seeds for reproducibility across all frameworks\n",
    "np.random.seed(42)  # NumPy random seed\n",
    "tf.random.set_seed(42)  # TensorFlow random seed\n",
    "\n",
    "print(\"=\"*80)  # Print separator line for visual clarity\n",
    "print(\"MEMBER 2: NAIVE BAYES AND DEEP LEARNING MODELS\")  # Print module header\n",
    "print(\"=\"*80)  # Print separator line for visual clarity\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: LOAD PREPROCESSED DATA AND SAVED ARTIFACTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n--- PHASE 1: LOADING PREPROCESSED DATA ---\")  # Announce data loading phase\n",
    "\n",
    "# Load the dataset to get original column information\n",
    "df = pd.read_csv('data/heart_cleveland_upload.csv')  # Load heart disease dataset\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')  # Standardize column names\n",
    "\n",
    "# Identify target column\n",
    "target_column = None  # Initialize target column variable\n",
    "if 'target' in df.columns:  # Check if 'target' column exists\n",
    "    target_column = 'target'  # Set target column name\n",
    "elif 'condition' in df.columns:  # Check if 'condition' column exists\n",
    "    target_column = 'condition'  # Set target column name\n",
    "else:  # If neither common name exists\n",
    "    target_column = df.columns[-1]  # Use last column as target\n",
    "\n",
    "print(f\"Target column: {target_column}\")  # Display target column name\n",
    "\n",
    "# Load preprocessor saved by Member 1\n",
    "preprocessor = joblib.load('artifacts/models/preprocessor.pkl')  # Load fitted preprocessor\n",
    "print(\"Preprocessor loaded successfully\")  # Confirm loading\n",
    "\n",
    "# Load train-test split saved by Member 1\n",
    "X_train, X_test, y_train, y_test = joblib.load('artifacts/models/train_test_split.pkl')  # Load split data\n",
    "print(f\" Train-test split loaded: {X_train.shape[0]} train, {X_test.shape[0]} test samples\")  # Confirm loading\n",
    "\n",
    "# Transform data using loaded preprocessor\n",
    "X_train_processed = preprocessor.transform(X_train)  # Transform training data\n",
    "X_test_processed = preprocessor.transform(X_test)  # Transform test data\n",
    "print(f\" Data preprocessed: {X_train_processed.shape[1]} features after transformation\")  # Display feature count\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: NAIVE BAYES MODEL WITH BOOTSTRAP CONFIDENCE INTERVALS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n--- PHASE 2: NAIVE BAYES MODEL ---\")  # Announce Naive Bayes phase\n",
    "\n",
    "# Initialize and train Gaussian Naive Bayes classifier\n",
    "nb_model = GaussianNB()  # Create Naive Bayes model\n",
    "nb_model.fit(X_train_processed, y_train)  # Train model on processed training data\n",
    "y_pred_nb = nb_model.predict(X_test_processed)  # Make predictions on test set\n",
    "y_pred_proba_nb = nb_model.predict_proba(X_test_processed)[:, 1]  # Get probability predictions for positive class\n",
    "\n",
    "# Calculate evaluation metrics for Naive Bayes\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)  # Calculate accuracy\n",
    "nb_precision = precision_score(y_test, y_pred_nb, average='binary', zero_division=0)  # Calculate precision\n",
    "nb_recall = recall_score(y_test, y_pred_nb, average='binary', zero_division=0)  # Calculate recall\n",
    "nb_f1 = f1_score(y_test, y_pred_nb, average='binary', zero_division=0)  # Calculate F1-score\n",
    "\n",
    "print(f\"\\nNaive Bayes Performance:\")  # Announce NB results\n",
    "print(f\"  Accuracy:  {nb_accuracy:.4f}\")  # Display accuracy\n",
    "print(f\"  Precision: {nb_precision:.4f}\")  # Display precision\n",
    "print(f\"  Recall:    {nb_recall:.4f}\")  # Display recall\n",
    "print(f\"  F1-Score:  {nb_f1:.4f}\")  # Display F1-score\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 2A: BOOTSTRAP CONFIDENCE INTERVALS FOR NAIVE BAYES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nCalculating Bootstrap Confidence Intervals (1000 iterations)...\")  # Announce bootstrap\n",
    "n_iterations = 1000  # Number of bootstrap iterations\n",
    "bootstrap_accuracies = []  # List to store bootstrap accuracy scores\n",
    "\n",
    "for i in range(n_iterations):  # Iterate through bootstrap samples\n",
    "    # Resample test set with replacement\n",
    "    X_test_boot, y_test_boot = resample(X_test_processed, y_test, random_state=i)  # Create bootstrap sample\n",
    "    y_pred_boot = nb_model.predict(X_test_boot)  # Make predictions on bootstrap sample\n",
    "    boot_acc = accuracy_score(y_test_boot, y_pred_boot)  # Calculate accuracy\n",
    "    bootstrap_accuracies.append(boot_acc)  # Store accuracy\n",
    "\n",
    "bootstrap_accuracies = np.array(bootstrap_accuracies)  # Convert to numpy array\n",
    "ci_lower = np.percentile(bootstrap_accuracies, 2.5)  # Calculate lower bound of 95% CI\n",
    "ci_upper = np.percentile(bootstrap_accuracies, 97.5)  # Calculate upper bound of 95% CI\n",
    "\n",
    "print(f\"Bootstrap Mean Accuracy: {bootstrap_accuracies.mean():.4f}\")  # Display mean accuracy\n",
    "print(f\"95% Confidence Interval: [{ci_lower:.4f}, {ci_upper:.4f}]\")  # Display confidence interval\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 2B: CONFUSION MATRIX FOR NAIVE BAYES\n",
    "# ============================================================================\n",
    "\n",
    "nb_cm = confusion_matrix(y_test, y_pred_nb)  # Calculate confusion matrix\n",
    "plt.figure(figsize=(8, 6))  # Create figure\n",
    "sns.heatmap(nb_cm, annot=True, fmt='d', cmap='Purples', cbar=True,  # Create heatmap\n",
    "            xticklabels=['No Disease', 'Disease'],  # Label x-axis\n",
    "            yticklabels=['No Disease', 'Disease'])  # Label y-axis\n",
    "plt.title('Naive Bayes - Confusion Matrix', fontsize=14, fontweight='bold')  # Add title\n",
    "plt.ylabel('Actual', fontsize=12)  # Label y-axis\n",
    "plt.xlabel('Predicted', fontsize=12)  # Label x-axis\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.savefig('artifacts/figures/nb_confusion_matrix.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"Naive Bayes confusion matrix saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 2C: ROC CURVE FOR NAIVE BAYES\n",
    "# ============================================================================\n",
    "\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, y_pred_proba_nb)  # Calculate ROC curve points\n",
    "roc_auc_nb = auc(fpr_nb, tpr_nb)  # Calculate area under ROC curve\n",
    "\n",
    "plt.figure(figsize=(8, 6))  # Create figure\n",
    "plt.plot(fpr_nb, tpr_nb, color='purple', lw=2, label=f'ROC curve (AUC = {roc_auc_nb:.2f})')  # Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')  # Plot diagonal reference\n",
    "plt.xlim([0.0, 1.0])  # Set x-axis limits\n",
    "plt.ylim([0.0, 1.05])  # Set y-axis limits\n",
    "plt.xlabel('False Positive Rate', fontsize=12)  # Label x-axis\n",
    "plt.ylabel('True Positive Rate', fontsize=12)  # Label y-axis\n",
    "plt.title('Naive Bayes - ROC Curve', fontsize=14, fontweight='bold')  # Add title\n",
    "plt.legend(loc=\"lower right\")  # Add legend\n",
    "plt.grid(alpha=0.3)  # Add grid\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.savefig('artifacts/figures/nb_roc_curve.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"Naive Bayes ROC curve saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 2D: PRECISION-RECALL CURVE FOR NAIVE BAYES\n",
    "# ============================================================================\n",
    "\n",
    "precision_nb, recall_nb, _ = precision_recall_curve(y_test, y_pred_proba_nb)  # Calculate PR curve points\n",
    "plt.figure(figsize=(8, 6))  # Create figure\n",
    "plt.plot(recall_nb, precision_nb, color='purple', lw=2, label='PR curve')  # Plot PR curve\n",
    "plt.xlabel('Recall', fontsize=12)  # Label x-axis\n",
    "plt.ylabel('Precision', fontsize=12)  # Label y-axis\n",
    "plt.title('Naive Bayes - Precision-Recall Curve', fontsize=14, fontweight='bold')  # Add title\n",
    "plt.legend(loc=\"lower left\")  # Add legend\n",
    "plt.grid(alpha=0.3)  # Add grid\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.savefig('artifacts/figures/nb_pr_curve.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"Naive Bayes PR curve saved\")  # Confirm save\n",
    "\n",
    "# Save Naive Bayes model and metrics\n",
    "joblib.dump(nb_model, 'artifacts/models/naive_bayes_model.pkl')  # Save trained model\n",
    "nb_metrics = {  # Create metrics dictionary\n",
    "    'model': 'Naive Bayes',  # Model name\n",
    "    'accuracy': float(nb_accuracy),  # Convert to float for JSON serialization\n",
    "    'precision': float(nb_precision),  # Convert to float\n",
    "    'recall': float(nb_recall),  # Convert to float\n",
    "    'f1_score': float(nb_f1),  # Convert to float\n",
    "    'roc_auc': float(roc_auc_nb),  # Convert to float\n",
    "    'bootstrap_mean': float(bootstrap_accuracies.mean()),  # Bootstrap mean\n",
    "    'ci_lower': float(ci_lower),  # Confidence interval lower bound\n",
    "    'ci_upper': float(ci_upper)  # Confidence interval upper bound\n",
    "}\n",
    "with open('artifacts/metrics/naive_bayes_metrics.json', 'w') as f:  # Open file for writing\n",
    "    json.dump(nb_metrics, f, indent=4)  # Save metrics as formatted JSON\n",
    "print(\"Naive Bayes model and metrics saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: MULTILAYER PERCEPTRON (MLP) ARTIFICIAL NEURAL NETWORK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n--- PHASE 3: MULTILAYER PERCEPTRON (ANN) ---\")  # Announce MLP phase\n",
    "\n",
    "# Build MLP architecture\n",
    "mlp_model = Sequential([  # Create sequential model\n",
    "    Dense(128, activation='relu', input_shape=(X_train_processed.shape[1],)),  # First hidden layer with 128 neurons\n",
    "    Dropout(0.3),  # Dropout layer to prevent overfitting\n",
    "    Dense(64, activation='relu'),  # Second hidden layer with 64 neurons\n",
    "    Dropout(0.3),  # Dropout layer\n",
    "    Dense(32, activation='relu'),  # Third hidden layer with 32 neurons\n",
    "    Dropout(0.2),  # Dropout layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
    "])\n",
    "\n",
    "# Compile MLP model\n",
    "mlp_model.compile(optimizer='adam',  # Use Adam optimizer\n",
    "                  loss='binary_crossentropy',  # Binary cross-entropy loss for binary classification\n",
    "                  metrics=['accuracy'])  # Track accuracy during training\n",
    "\n",
    "print(\"\\nMLP Model Architecture:\")  # Announce architecture summary\n",
    "mlp_model.summary()  # Display model architecture\n",
    "\n",
    "# Define early stopping callback to prevent overfitting\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)  # Stop if no improvement\n",
    "\n",
    "# Train MLP model\n",
    "print(\"\\nTraining MLP model...\")  # Announce training\n",
    "mlp_history = mlp_model.fit(X_train_processed, y_train,  # Train on processed data\n",
    "                             epochs=100,  # Maximum number of epochs\n",
    "                             batch_size=32,  # Batch size for training\n",
    "                             validation_split=0.2,  # Use 20% of training data for validation\n",
    "                             callbacks=[early_stop],  # Use early stopping\n",
    "                             verbose=0)  # Suppress detailed output\n",
    "\n",
    "print(f\" MLP training completed in {len(mlp_history.history['loss'])} epochs\")  # Display epochs trained\n",
    "\n",
    "# Make predictions with MLP\n",
    "y_pred_proba_mlp = mlp_model.predict(X_test_processed).ravel()  # Get probability predictions\n",
    "y_pred_mlp = (y_pred_proba_mlp > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate evaluation metrics for MLP\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred_mlp)  # Calculate accuracy\n",
    "mlp_precision = precision_score(y_test, y_pred_mlp, average='binary', zero_division=0)  # Calculate precision\n",
    "mlp_recall = recall_score(y_test, y_pred_mlp, average='binary', zero_division=0)  # Calculate recall\n",
    "mlp_f1 = f1_score(y_test, y_pred_mlp, average='binary', zero_division=0)  # Calculate F1-score\n",
    "\n",
    "print(f\"\\nMLP Performance:\")  # Announce MLP results\n",
    "print(f\"  Accuracy:  {mlp_accuracy:.4f}\")  # Display accuracy\n",
    "print(f\"  Precision: {mlp_precision:.4f}\")  # Display precision\n",
    "print(f\"  Recall:    {mlp_recall:.4f}\")  # Display recall\n",
    "print(f\"  F1-Score:  {mlp_f1:.4f}\")  # Display F1-score\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 3A: TRAINING CURVES FOR MLP\n",
    "# ============================================================================\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))  # Create figure with two subplots\n",
    "\n",
    "# Plot training and validation loss\n",
    "ax1.plot(mlp_history.history['loss'], label='Training Loss', color='blue', linewidth=2)  # Plot training loss\n",
    "ax1.plot(mlp_history.history['val_loss'], label='Validation Loss', color='red', linewidth=2)  # Plot validation loss\n",
    "ax1.set_xlabel('Epoch', fontsize=12)  # Label x-axis\n",
    "ax1.set_ylabel('Loss', fontsize=12)  # Label y-axis\n",
    "ax1.set_title('MLP - Loss Curves', fontsize=14, fontweight='bold')  # Add title\n",
    "ax1.legend()  # Add legend\n",
    "ax1.grid(alpha=0.3)  # Add grid\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "ax2.plot(mlp_history.history['accuracy'], label='Training Accuracy', color='blue', linewidth=2)  # Plot train accuracy\n",
    "ax2.plot(mlp_history.history['val_accuracy'], label='Validation Accuracy', color='red', linewidth=2)  # Plot val accuracy\n",
    "ax2.set_xlabel('Epoch', fontsize=12)  # Label x-axis\n",
    "ax2.set_ylabel('Accuracy', fontsize=12)  # Label y-axis\n",
    "ax2.set_title('MLP - Accuracy Curves', fontsize=14, fontweight='bold')  # Add title\n",
    "ax2.legend()  # Add legend\n",
    "ax2.grid(alpha=0.3)  # Add grid\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing\n",
    "plt.savefig('artifacts/figures/mlp_training_curves.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"MLP training curves saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 3B: CONFUSION MATRIX FOR MLP\n",
    "# ============================================================================\n",
    "\n",
    "mlp_cm = confusion_matrix(y_test, y_pred_mlp)  # Calculate confusion matrix\n",
    "plt.figure(figsize=(8, 6))  # Create figure\n",
    "sns.heatmap(mlp_cm, annot=True, fmt='d', cmap='Oranges', cbar=True,  # Create heatmap\n",
    "            xticklabels=['No Disease', 'Disease'],  # Label x-axis\n",
    "            yticklabels=['No Disease', 'Disease'])  # Label y-axis\n",
    "plt.title('MLP - Confusion Matrix', fontsize=14, fontweight='bold')  # Add title\n",
    "plt.ylabel('Actual', fontsize=12)  # Label y-axis\n",
    "plt.xlabel('Predicted', fontsize=12)  # Label x-axis\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.savefig('artifacts/figures/mlp_confusion_matrix.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"MLP confusion matrix saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 3C: ROC CURVE FOR MLP\n",
    "# ============================================================================\n",
    "\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_test, y_pred_proba_mlp)  # Calculate ROC curve points\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)  # Calculate area under ROC curve\n",
    "\n",
    "plt.figure(figsize=(8, 6))  # Create figure\n",
    "plt.plot(fpr_mlp, tpr_mlp, color='orange', lw=2, label=f'ROC curve (AUC = {roc_auc_mlp:.2f})')  # Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')  # Plot diagonal reference\n",
    "plt.xlim([0.0, 1.0])  # Set x-axis limits\n",
    "plt.ylim([0.0, 1.05])  # Set y-axis limits\n",
    "plt.xlabel('False Positive Rate', fontsize=12)  # Label x-axis\n",
    "plt.ylabel('True Positive Rate', fontsize=12)  # Label y-axis\n",
    "plt.title('MLP - ROC Curve', fontsize=14, fontweight='bold')  # Add title\n",
    "plt.legend(loc=\"lower right\")  # Add legend\n",
    "plt.grid(alpha=0.3)  # Add grid\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.savefig('artifacts/figures/mlp_roc_curve.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"MLP ROC curve saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 3D: PRECISION-RECALL CURVE FOR MLP\n",
    "# ============================================================================\n",
    "\n",
    "precision_mlp, recall_mlp, _ = precision_recall_curve(y_test, y_pred_proba_mlp)  # Calculate PR curve points\n",
    "plt.figure(figsize=(8, 6))  # Create figure\n",
    "plt.plot(recall_mlp, precision_mlp, color='orange', lw=2, label='PR curve')  # Plot PR curve\n",
    "plt.xlabel('Recall', fontsize=12)  # Label x-axis\n",
    "plt.ylabel('Precision', fontsize=12)  # Label y-axis\n",
    "plt.title('MLP - Precision-Recall Curve', fontsize=14, fontweight='bold')  # Add title\n",
    "plt.legend(loc=\"lower left\")  # Add legend\n",
    "plt.grid(alpha=0.3)  # Add grid\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.savefig('artifacts/figures/mlp_pr_curve.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"MLP PR curve saved\")  # Confirm save\n",
    "\n",
    "# Save MLP model and metrics\n",
    "mlp_model.save('artifacts/models/mlp_model.h5')  # Save trained Keras model\n",
    "mlp_metrics = {  # Create metrics dictionary\n",
    "    'model': 'MLP (ANN)',  # Model name\n",
    "    'accuracy': float(mlp_accuracy),  # Convert to float for JSON serialization\n",
    "    'precision': float(mlp_precision),  # Convert to float\n",
    "    'recall': float(mlp_recall),  # Convert to float\n",
    "    'f1_score': float(mlp_f1),  # Convert to float\n",
    "    'roc_auc': float(roc_auc_mlp),  # Convert to float\n",
    "    'epochs_trained': len(mlp_history.history['loss']),  # Number of epochs\n",
    "    'final_train_loss': float(mlp_history.history['loss'][-1]),  # Final training loss\n",
    "    'final_val_loss': float(mlp_history.history['val_loss'][-1])  # Final validation loss\n",
    "}\n",
    "with open('artifacts/metrics/mlp_metrics.json', 'w') as f:  # Open file for writing\n",
    "    json.dump(mlp_metrics, f, indent=4)  # Save metrics as formatted JSON\n",
    "print(\"MLP model and metrics saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: LSTM MODEL (ADVANCED EXTENSION)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n--- PHASE 4: LSTM MODEL (ADVANCED EXTENSION) ---\")  # Announce LSTM phase\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X_train_lstm = X_train_processed.reshape((X_train_processed.shape[0], 1, X_train_processed.shape[1]))  # Reshape training\n",
    "X_test_lstm = X_test_processed.reshape((X_test_processed.shape[0], 1, X_test_processed.shape[1]))  # Reshape test\n",
    "\n",
    "print(f\"LSTM input shape: {X_train_lstm.shape}\")  # Display reshaped input dimensions\n",
    "\n",
    "# Build LSTM architecture\n",
    "lstm_model = Sequential([  # Create sequential model\n",
    "    LSTM(64, activation='tanh', return_sequences=True, input_shape=(1, X_train_processed.shape[1])),  # First LSTM layer\n",
    "    Dropout(0.3),  # Dropout layer\n",
    "    LSTM(32, activation='tanh'),  # Second LSTM layer\n",
    "    Dropout(0.3),  # Dropout layer\n",
    "    Dense(16, activation='relu'),  # Dense hidden layer\n",
    "    Dropout(0.2),  # Dropout layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid\n",
    "])\n",
    "\n",
    "# Compile LSTM model\n",
    "lstm_model.compile(optimizer='adam',  # Use Adam optimizer\n",
    "                   loss='binary_crossentropy',  # Binary cross-entropy loss\n",
    "                   metrics=['accuracy'])  # Track accuracy\n",
    "\n",
    "print(\"\\nLSTM Model Architecture:\")  # Announce architecture summary\n",
    "lstm_model.summary()  # Display model architecture\n",
    "\n",
    "# Train LSTM model\n",
    "print(\"\\nTraining LSTM model...\")  # Announce training\n",
    "lstm_history = lstm_model.fit(X_train_lstm, y_train,  # Train on reshaped data\n",
    "                               epochs=100,  # Maximum number of epochs\n",
    "                               batch_size=32,  # Batch size for training\n",
    "                               validation_split=0.2,  # Use 20% for validation\n",
    "                               callbacks=[early_stop],  # Use early stopping\n",
    "                               verbose=0)  # Suppress detailed output\n",
    "\n",
    "print(f\" LSTM training completed in {len(lstm_history.history['loss'])} epochs\")  # Display epochs trained\n",
    "\n",
    "# Make predictions with LSTM\n",
    "y_pred_proba_lstm = lstm_model.predict(X_test_lstm).ravel()  # Get probability predictions\n",
    "y_pred_lstm = (y_pred_proba_lstm > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate evaluation metrics for LSTM\n",
    "lstm_accuracy = accuracy_score(y_test, y_pred_lstm)  # Calculate accuracy\n",
    "lstm_precision = precision_score(y_test, y_pred_lstm, average='binary', zero_division=0)  # Calculate precision\n",
    "lstm_recall = recall_score(y_test, y_pred_lstm, average='binary', zero_division=0)  # Calculate recall\n",
    "lstm_f1 = f1_score(y_test, y_pred_lstm, average='binary', zero_division=0)  # Calculate F1-score\n",
    "\n",
    "print(f\"\\nLSTM Performance:\")  # Announce LSTM results\n",
    "print(f\"  Accuracy:  {lstm_accuracy:.4f}\")  # Display accuracy\n",
    "print(f\"  Precision: {lstm_precision:.4f}\")  # Display precision\n",
    "print(f\"  Recall:    {lstm_recall:.4f}\")  # Display recall\n",
    "print(f\"  F1-Score:  {lstm_f1:.4f}\")  # Display F1-score\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 4A: TRAINING CURVES FOR LSTM\n",
    "# ============================================================================\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))  # Create figure with two subplots\n",
    "\n",
    "# Plot training and validation loss\n",
    "ax1.plot(lstm_history.history['loss'], label='Training Loss', color='blue', linewidth=2)  # Plot training loss\n",
    "ax1.plot(lstm_history.history['val_loss'], label='Validation Loss', color='red', linewidth=2)  # Plot validation loss\n",
    "ax1.set_xlabel('Epoch', fontsize=12)  # Label x-axis\n",
    "ax1.set_ylabel('Loss', fontsize=12)  # Label y-axis\n",
    "ax1.set_title('LSTM - Loss Curves', fontsize=14, fontweight='bold')  # Add title\n",
    "ax1.legend()  # Add legend\n",
    "ax1.grid(alpha=0.3)  # Add grid\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "ax2.plot(lstm_history.history['accuracy'], label='Training Accuracy', color='blue', linewidth=2)  # Plot train accuracy\n",
    "ax2.plot(lstm_history.history['val_accuracy'], label='Validation Accuracy', color='red', linewidth=2)  # Plot val accuracy\n",
    "ax2.set_xlabel('Epoch', fontsize=12)  # Label x-axis\n",
    "ax2.set_ylabel('Accuracy', fontsize=12)  # Label y-axis\n",
    "ax2.set_title('LSTM - Accuracy Curves', fontsize=14, fontweight='bold')  # Add title\n",
    "ax2.legend()  # Add legend\n",
    "ax2.grid(alpha=0.3)  # Add grid\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing\n",
    "plt.savefig('artifacts/figures/lstm_training_curves.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"LSTM training curves saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 4B: CONFUSION MATRIX FOR LSTM\n",
    "# ============================================================================\n",
    "\n",
    "lstm_cm = confusion_matrix(y_test, y_pred_lstm)  # Calculate confusion matrix\n",
    "plt.figure(figsize=(8, 6))  # Create figure\n",
    "sns.heatmap(lstm_cm, annot=True, fmt='d', cmap='YlOrRd', cbar=True,  # Create heatmap\n",
    "            xticklabels=['No Disease', 'Disease'],  # Label x-axis\n",
    "            yticklabels=['No Disease', 'Disease'])  # Label y-axis\n",
    "plt.title('LSTM - Confusion Matrix', fontsize=14, fontweight='bold')  # Add title\n",
    "plt.ylabel('Actual', fontsize=12)  # Label y-axis\n",
    "plt.xlabel('Predicted', fontsize=12)  # Label x-axis\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.savefig('artifacts/figures/lstm_confusion_matrix.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"LSTM confusion matrix saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 4C: ROC CURVE FOR LSTM\n",
    "# ============================================================================\n",
    "\n",
    "fpr_lstm, tpr_lstm, _ = roc_curve(y_test, y_pred_proba_lstm)  # Calculate ROC curve points\n",
    "roc_auc_lstm = auc(fpr_lstm, tpr_lstm)  # Calculate area under ROC curve\n",
    "\n",
    "plt.figure(figsize=(8, 6))  # Create figure\n",
    "plt.plot(fpr_lstm, tpr_lstm, color='red', lw=2, label=f'ROC curve (AUC = {roc_auc_lstm:.2f})')  # Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')  # Plot diagonal reference\n",
    "plt.xlim([0.0, 1.0])  # Set x-axis limits\n",
    "plt.ylim([0.0, 1.05])  # Set y-axis limits\n",
    "plt.xlabel('False Positive Rate', fontsize=12)  # Label x-axis\n",
    "plt.ylabel('True Positive Rate', fontsize=12)  # Label y-axis\n",
    "plt.title('LSTM - ROC Curve', fontsize=14, fontweight='bold')  # Add title\n",
    "plt.legend(loc=\"lower right\")  # Add legend\n",
    "plt.grid(alpha=0.3)  # Add grid\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.savefig('artifacts/figures/lstm_roc_curve.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"LSTM ROC curve saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 4D: PRECISION-RECALL CURVE FOR LSTM\n",
    "# ============================================================================\n",
    "\n",
    "precision_lstm, recall_lstm, _ = precision_recall_curve(y_test, y_pred_proba_lstm)  # Calculate PR curve points\n",
    "plt.figure(figsize=(8, 6))  # Create figure\n",
    "plt.plot(recall_lstm, precision_lstm, color='red', lw=2, label='PR curve')  # Plot PR curve\n",
    "plt.xlabel('Recall', fontsize=12)  # Label x-axis\n",
    "plt.ylabel('Precision', fontsize=12)  # Label y-axis\n",
    "plt.title('LSTM - Precision-Recall Curve', fontsize=14, fontweight='bold')  # Add title\n",
    "plt.legend(loc=\"lower left\")  # Add legend\n",
    "plt.grid(alpha=0.3)  # Add grid\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.savefig('artifacts/figures/lstm_pr_curve.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"LSTM PR curve saved\")  # Confirm save\n",
    "\n",
    "# Save LSTM model and metrics\n",
    "lstm_model.save('artifacts/models/lstm_model.h5')  # Save trained Keras model\n",
    "lstm_metrics = {  # Create metrics dictionary\n",
    "    'model': 'LSTM',  # Model name\n",
    "    'accuracy': float(lstm_accuracy),  # Convert to float for JSON serialization\n",
    "    'precision': float(lstm_precision),  # Convert to float\n",
    "    'recall': float(lstm_recall),  # Convert to float\n",
    "    'f1_score': float(lstm_f1),  # Convert to float\n",
    "    'roc_auc': float(roc_auc_lstm),  # Convert to float\n",
    "    'epochs_trained': len(lstm_history.history['loss']),  # Number of epochs\n",
    "    'final_train_loss': float(lstm_history.history['loss'][-1]),  # Final training loss\n",
    "    'final_val_loss': float(lstm_history.history['val_loss'][-1])  # Final validation loss\n",
    "}\n",
    "with open('artifacts/metrics/lstm_metrics.json', 'w') as f:  # Open file for writing\n",
    "    json.dump(lstm_metrics, f, indent=4)  # Save metrics as formatted JSON\n",
    "print(\"LSTM model and metrics saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 6: AGGREGATE ALL METRICS AND CREATE COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n--- PHASE 5: AGGREGATING METRICS ---\")  # Announce aggregation phase\n",
    "\n",
    "# Load all metric JSON files\n",
    "metric_files = glob.glob('artifacts/metrics/*_metrics.json')  # Find all metric JSON files\n",
    "all_metrics = []  # List to store all metrics\n",
    "\n",
    "for file in metric_files:  # Iterate through metric files\n",
    "    with open(file, 'r') as f:  # Open file for reading\n",
    "        metrics = json.load(f)  # Load metrics from JSON\n",
    "        all_metrics.append(metrics)  # Add to list\n",
    "\n",
    "# Create DataFrame from all metrics\n",
    "metrics_df = pd.DataFrame(all_metrics)  # Convert list of dicts to DataFrame\n",
    "metrics_df = metrics_df[['model', 'accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']]  # Select key columns\n",
    "metrics_df = metrics_df.sort_values('accuracy', ascending=False)  # Sort by accuracy descending\n",
    "\n",
    "# Save aggregated metrics to CSV\n",
    "metrics_df.to_csv('artifacts/metrics/all_models_comparison.csv', index=False)  # Save to CSV file\n",
    "print(\"\\n Aggregated metrics saved to all_models_comparison.csv\")  # Confirm save\n",
    "\n",
    "print(\"\\nAll Models Performance Comparison:\")  # Announce comparison table\n",
    "print(metrics_df.to_string(index=False))  # Display formatted table\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 5A: CREATE COMPARISON BAR CHART\n",
    "# ============================================================================\n",
    "\n",
    "# Prepare data for visualization\n",
    "models = metrics_df['model'].tolist()  # Extract model names\n",
    "accuracy_scores = metrics_df['accuracy'].tolist()  # Extract accuracy scores\n",
    "precision_scores = metrics_df['precision'].tolist()  # Extract precision scores\n",
    "recall_scores = metrics_df['recall'].tolist()  # Extract recall scores\n",
    "f1_scores = metrics_df['f1_score'].tolist()  # Extract F1 scores\n",
    "\n",
    "# Set up bar chart parameters\n",
    "x = np.arange(len(models))  # Create x-axis positions\n",
    "width = 0.2  # Width of each bar\n",
    "\n",
    "# Create figure and bar chart\n",
    "fig, ax = plt.subplots(figsize=(14, 8))  # Create large figure\n",
    "bar1 = ax.bar(x - 1.5*width, accuracy_scores, width, label='Accuracy', color='#2E86AB')  # Accuracy bars\n",
    "bar2 = ax.bar(x - 0.5*width, precision_scores, width, label='Precision', color='#A23B72')  # Precision bars\n",
    "bar3 = ax.bar(x + 0.5*width, recall_scores, width, label='Recall', color='#F18F01')  # Recall bars\n",
    "bar4 = ax.bar(x + 1.5*width, f1_scores, width, label='F1-Score', color='#C73E1D')  # F1-Score bars\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bars in [bar1, bar2, bar3, bar4]:  # Iterate through bar groups\n",
    "    for bar in bars:  # Iterate through individual bars\n",
    "        height = bar.get_height()  # Get bar height\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,  # Position text\n",
    "                f'{height:.3f}',  # Format value to 3 decimals\n",
    "                ha='center', va='bottom', fontsize=9)  # Set text alignment and size\n",
    "\n",
    "# Customize chart appearance\n",
    "ax.set_xlabel('Models', fontsize=14, fontweight='bold')  # Label x-axis\n",
    "ax.set_ylabel('Score', fontsize=14, fontweight='bold')  # Label y-axis\n",
    "ax.set_title('Performance Comparison Across All Models', fontsize=16, fontweight='bold')  # Add title\n",
    "ax.set_xticks(x)  # Set x-axis tick positions\n",
    "ax.set_xticklabels(models, fontsize=11)  # Set x-axis tick labels\n",
    "ax.legend(fontsize=11, loc='lower right')  # Add legend\n",
    "ax.set_ylim([0, 1.1])  # Set y-axis limits\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')  # Add horizontal grid lines\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, alpha=0.5)  # Add reference line at 0.5\n",
    "\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.savefig('artifacts/figures/all_models_comparison.png', dpi=300, bbox_inches='tight')  # Save figure\n",
    "plt.close()  # Close figure\n",
    "print(\"Comparison bar chart saved\")  # Confirm save\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 7: SUMMARY AND COMPLETION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)  # Print separator line\n",
    "print(\"MEMBER 2 COMPLETION SUMMARY\")  # Print summary header\n",
    "print(\"=\"*80)  # Print separator line\n",
    "print(\"\\n Naive Bayes trained and evaluated with bootstrap CI\")  # Confirm NB completion\n",
    "print(\"MLP (ANN) trained and evaluated with training curves\")  # Confirm MLP completion\n",
    "print(\"LSTM trained and evaluated with training curves\")  # Confirm LSTM completion\n",
    "print(\"All models saved to artifacts/models/\")  # Confirm model saves\n",
    "print(\"All metrics saved to artifacts/metrics/\")  # Confirm metrics saves\n",
    "print(\"All figures saved to artifacts/figures/\")  # Confirm figure saves\n",
    "print(\"Aggregated comparison CSV and chart created\")  # Confirm aggregation\n",
    "\n",
    "print(\"\\nFinal Model Rankings (by Accuracy):\")  # Announce rankings\n",
    "for idx, row in metrics_df.iterrows():  # Iterate through sorted dataframe\n",
    "    print(f\"  {idx+1}. {row['model']}: {row['accuracy']:.4f}\")  # Display rank and accuracy\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)  # Print separator line\n",
    "print(\"ALL MODELS READY FOR PRESENTATION\")  # Print completion message\n",
    "print(\"=\"*80)  # Print separator line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
